{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju6xqhsJw-MR"
      },
      "source": [
        "## GPU Demos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kCq-WoUUDRV"
      },
      "source": [
        "### Install and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "calQiUxRUIlk"
      },
      "source": [
        "Do a `pip install` of the [numba](https://numba.pydata.org/) library and check for where the cuda `.so` files are kept.  If a `.so` appears CUDA is likely installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9_HoXwERH1i",
        "outputId": "e38453b3-5cbc-4077-f85c-b0f5c64ef4aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numba\n",
            "  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /media/sdb1/anaconda3/envs/crypten/lib/python3.7/site-packages (from numba) (52.0.0.post20210125)\n",
            "Collecting numpy<1.21,>=1.17\n",
            "  Using cached numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
            "Collecting llvmlite<0.38,>=0.37.0rc1\n",
            "  Downloading llvmlite-0.37.0-cp37-cp37m-manylinux2014_x86_64.whl (26.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, llvmlite, numba\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.2\n",
            "    Uninstalling numpy-1.21.2:\n",
            "      Successfully uninstalled numpy-1.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.20.3 which is incompatible.\u001b[0m\n",
            "Successfully installed llvmlite-0.37.0 numba-0.54.1 numpy-1.20.3\n",
            "/var/lib/docker/overlay2/1c2ffe0fc1eae0471e8f1e481b3d5f7dfa423b8ac4e9ad95ae79ccf9a7e34847/diff/usr/local/cuda-10.0/nvvm/libdevice\n",
            "/var/lib/docker/overlay2/a3c830f3b106269d4d3bf4296d6e398983a01f83781a801f1c6ef033fa9b943c/diff/usr/local/cuda-9.0/nvvm/libdevice\n",
            "/var/lib/docker/overlay2/40828fa6b89d0389f20e9cd00ea3abf4ad0f80a27ea5473fef26d6155e15dfa9/diff/usr/local/cuda-10.2/nvvm/libdevice\n",
            "/var/lib/docker/overlay2/40828fa6b89d0389f20e9cd00ea3abf4ad0f80a27ea5473fef26d6155e15dfa9/diff/usr/local/cuda-10.2/nvvmx/libdevice\n",
            "/var/lib/docker/overlay2/aa9c20bab0c6801cd57e8fb84f0d655d8cd7736c53e13d89402183e5725030d5/diff/usr/local/cuda-10.2/nvvm/libdevice\n",
            "/var/lib/docker/overlay2/aa9c20bab0c6801cd57e8fb84f0d655d8cd7736c53e13d89402183e5725030d5/diff/usr/local/cuda-10.2/nvvmx/libdevice\n",
            "/var/lib/docker/overlay2/dd686b5a12cd56ab0c71823447783ea062bbf1abc73e4a07858c58fbd3a3d7c7/diff/usr/local/cuda-10.2/nvvm/libdevice\n",
            "/var/lib/docker/overlay2/dd686b5a12cd56ab0c71823447783ea062bbf1abc73e4a07858c58fbd3a3d7c7/diff/usr/local/cuda-10.2/nvvmx/libdevice\n",
            "find: ‘/proc/45039/task/45039/net’: Invalid argument\n",
            "find: ‘/proc/45039/net’: Invalid argument\n",
            "/usr/local/cuda-10.2/nvvm/libdevice\n",
            "/usr/local/cuda-10.2/nvvmx/libdevice\n",
            "/media/sdb1/anaconda3/envs/fl-3-7/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/envs/crypten/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/envs/mxnet_env/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/envs/tf_fl/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/pkgs/cudatoolkit-9.0-h13b8566_0/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/pkgs/cudatoolkit-10.2.89-hfd86e86_1/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/pkgs/cudatoolkit-10.1.243-h6bb024c_0/lib/libnvvm.so\n",
            "/media/sdb1/anaconda3/pkgs/cudatoolkit-11.0.221-h6bb024c_0/lib/libnvvm.so\n",
            "/var/lib/docker/overlay2/1c2ffe0fc1eae0471e8f1e481b3d5f7dfa423b8ac4e9ad95ae79ccf9a7e34847/diff/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
            "/var/lib/docker/overlay2/a3c830f3b106269d4d3bf4296d6e398983a01f83781a801f1c6ef033fa9b943c/diff/usr/local/cuda-9.0/nvvm/lib64/libnvvm.so\n",
            "/var/lib/docker/overlay2/40828fa6b89d0389f20e9cd00ea3abf4ad0f80a27ea5473fef26d6155e15dfa9/diff/usr/local/cuda-10.2/nvvm/lib64/libnvvm.so\n",
            "/var/lib/docker/overlay2/40828fa6b89d0389f20e9cd00ea3abf4ad0f80a27ea5473fef26d6155e15dfa9/diff/usr/local/cuda-10.2/nvvmx/lib64/libnvvm.so\n",
            "/var/lib/docker/overlay2/aa9c20bab0c6801cd57e8fb84f0d655d8cd7736c53e13d89402183e5725030d5/diff/usr/local/cuda-10.2/nvvm/lib64/libnvvm.so\n",
            "/var/lib/docker/overlay2/aa9c20bab0c6801cd57e8fb84f0d655d8cd7736c53e13d89402183e5725030d5/diff/usr/local/cuda-10.2/nvvmx/lib64/libnvvm.so\n",
            "/var/lib/docker/overlay2/41bc146ce5233d87b408d4fdf7b80f072520021d6d2ac1fa9028acd6587cb4fe/diff/opt/conda/pkgs/cudatoolkit-10.2.89-h6bb024c_0/lib/libnvvm.so\n",
            "/var/lib/docker/overlay2/41bc146ce5233d87b408d4fdf7b80f072520021d6d2ac1fa9028acd6587cb4fe/diff/opt/conda/lib/libnvvm.so\n",
            "/var/lib/docker/overlay2/dd686b5a12cd56ab0c71823447783ea062bbf1abc73e4a07858c58fbd3a3d7c7/diff/usr/local/cuda-10.2/nvvm/lib64/libnvvm.so\n",
            "/var/lib/docker/overlay2/dd686b5a12cd56ab0c71823447783ea062bbf1abc73e4a07858c58fbd3a3d7c7/diff/usr/local/cuda-10.2/nvvmx/lib64/libnvvm.so\n",
            "/home/pcl002/.conda/envs/cfr/lib/libnvvm.so\n",
            "/home/pcl002/.conda/pkgs/cudatoolkit-10.2.89-hfd86e86_1/lib/libnvvm.so\n",
            "find: ‘/proc/31554’: No such file or directory\n",
            "find: ‘/proc/31626’: No such file or directory\n",
            "find: ‘/proc/45039/task/45039/net’: Invalid argument\n",
            "find: ‘/proc/45039/net’: Invalid argument\n",
            "/usr/local/cuda-10.2/nvvm/lib64/libnvvm.so\n",
            "/usr/local/cuda-10.2/nvvmx/lib64/libnvvm.so\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2021.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 705 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting appdirs>=1.4.0\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2021.2.9.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.0 in /media/sdb1/anaconda3/envs/crypten/lib/python3.7/site-packages (from pytools>=2011.2->pycuda) (1.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /media/sdb1/anaconda3/envs/crypten/lib/python3.7/site-packages (from mako->pycuda) (2.0.0)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=629356 sha256=64536c5736ba8ba075ca83129ddb7e937f8e41a2ad4251035798f99185a02b1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/ef/49/dc6a5feb8d980b37c83d465ecab24949a6aa19458522a9e001\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pytools: filename=pytools-2021.2.9-py2.py3-none-any.whl size=62355 sha256=807d6031025f8577e3cfd44543dd242cfc49c32adac282a6c22a88465dda0fb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/b9/6e/94bb014f6484b15ec77e7877f3a227609481ffd98db364504d\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.6 pycuda-2021.1 pytools-2021.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install numba\n",
        "!find / -iname 'libdevice'\n",
        "!find / -iname 'libnvvm.so'\n",
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BknYtVD3U3JO"
      },
      "source": [
        "Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9SNbTzTF9VQ",
        "outputId": "31af32bf-c08d-41f5-bd2e-33a3c170851d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 30 03:28:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
            "| 16%   33C    P2    64W / 250W |   5864MiB / 11019MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
            "| 16%   27C    P8    29W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|    0     28919      C   python                                      1167MiB |\n",
            "|    0     33784      C   python                                      1169MiB |\n",
            "|    0     39354      C   python                                      1167MiB |\n",
            "|    0     44617      C   python                                      1167MiB |\n",
            "|    0     45038      C   ...cl001/anaconda3/envs/crypten/bin/python  1183MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RizeFcTRRSBP"
      },
      "outputs": [],
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import gpuarray\n",
        "import numpy as np\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VGjBbK65b9_7"
      },
      "outputs": [],
      "source": [
        "ker = \"\"\"\n",
        "  __device__ void swap(int & a, int & b){\n",
        "    int tmp = a;\n",
        "    a = b;\n",
        "    b = tmp;\n",
        "}\n",
        "\n",
        "__global__ void bitonicSort(int * A, int N){\n",
        "    extern __shared__ int shared[];\n",
        "\t\tint tid = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    // Copy input to shared mem.\n",
        "    shared[tid] = A[tid];\n",
        "    __syncthreads();\n",
        "    // Parallel bitonic sort.\n",
        "    for (int k = 2; k <= N; k *= 2){\n",
        "        // Bitonic merge:\n",
        "        for (int j = k / 2; j>0; j /= 2){\n",
        "            int ixj = tid ^ j;\n",
        "            if (ixj > tid){\n",
        "                if ((tid & k) == 0){\n",
        "                    if (shared[tid] > shared[ixj]){\n",
        "                        swap(shared[tid], shared[ixj]);\n",
        "                    }\n",
        "                }\n",
        "                else{\n",
        "                    if (shared[tid] < shared[ixj]){\n",
        "                        swap(shared[tid], shared[ixj]);\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "    }\n",
        "    // Write result.\n",
        "    A[tid] = shared[tid];\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmRHvDR672U6",
        "outputId": "655a66cb-2212-4f39-86a4-b1033337bd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution Time 0.0029528141021728516\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2\n",
            "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
            "  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
            "  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
            "  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
            "  8  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9\n",
            "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10\n",
            " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
            " 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15\n",
            " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
            " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18\n",
            " 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
            " 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
            " 19 19 19 19 19 19 19 19]\n"
          ]
        }
      ],
      "source": [
        "N = 512 #lenght of A\n",
        "A = np.int32(np.random.randint(1, 20, N)) #random numbers in A\n",
        "BLOCK_SIZE = N\n",
        "NUM_BLOCKS = (N + BLOCK_SIZE-1)//BLOCK_SIZE\n",
        "mod = SourceModule(ker)\n",
        "bitonicSort = mod.get_function(\"bitonicSort\")\n",
        "t1 = time()\n",
        "bitonicSort(drv.InOut(A), np.int32(N), block=(BLOCK_SIZE,1,1), grid=(NUM_BLOCKS,1), shared=4*N)\n",
        "t2 = time()\n",
        "print(\"Execution Time {0}\".format(t2 - t1))\n",
        "print(A)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab 3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
